# EX-02-Cross-Platform-Prompting-Evaluating-Diverse-Techniques-in-AI-Powered-Text-Summarization

## Name: Hafeezul Deen S
## Register No.: 212223220028

# AIM
To evaluate and compare the effectiveness of prompting techniques (zero-shot, few-shot, chain-of-thought, role-based) across different AI platforms (e.g., ChatGPT, Gemini, Claude, Copilot) in a specific task: text summarization.

# Scenario:
You are part of a content curation team for an educational platform that delivers quick summaries of research papers to undergraduate students. Your task is to summarize a 500-word technical article on "The Basics of Blockchain Technology" using multiple AI platforms and prompting strategies.

Your goal is to determine which combination of prompting technique + platform provides the best summary in terms of:

Accuracy

Coherence

Simplicity

Speed

User experience

# Algorithm

## 1.Define Use Case
Identify a realistic personalization scenario (e.g., product recommendations based on user behavior).

## 2.Select Prompt Types
Choose three distinct prompting strategies:

Straightforward Prompt Tabular Format Prompt Missing Word Prompt

## 3.Design Prompts
Write specific prompt examples aligned with the use case for each strategy.

## 4.Submit to Platforms
Run each prompt through two different AI platforms (ChatGPT and Claude).

## 5.Collect Outputs
Record the responses generated by each platform.

## 6.Evaluate Criteria
Assess each output based on: Relevance Coherence Customization Depth Responsiveness Tone

## 7.Compare and Recommend
Identify the best-performing combinations and suggest practical applications.


# Evaluation and Comparison of Prompting Techniques Across AI Platforms for Text Summarization
## 1. Introduction
This study examines how different prompting strategies—zero-shot, few-shot, chain-of-thought (CoT), and role-based—affect the quality of AI-generated summaries across four platforms: ChatGPT, Gemini, Claude, and Copilot. The technical article selected for summarization, “The Basics of Blockchain Technology”, is approximately 500 words long. The objective is to identify which combination of platform and prompting method produces the best summaries in terms of accuracy, coherence, simplicity, speed, and user experience for undergraduate students.

## 2. Evaluation Framework

### 2.1 Task Definition
Summarize a technical article into a concise, 150-word summary.
Target audience: Undergraduate students seeking quick, understandable overviews.

### 2.2 Prompting Techniques
Zero-Shot – Direct request to summarize without examples.
Few-Shot – Provide 2–3 sample text-summary pairs before summarization.
Chain-of-Thought (CoT) – Ask the AI to reason step-by-step (e.g., identify key points first, then summarize).
Role-Based – Assign a persona (e.g., “You are a university professor summarizing for first-year students…”).

### 2.3 Evaluation Metrics
Accuracy – Faithfulness to source content without hallucination.
Coherence – Logical structure and readability of the summary.
Simplicity – Use of clear, concise language appropriate for undergraduates.
Speed – Time taken by each model to generate the output.
User Experience (UX) – Ease of interaction, clarity of response, and formatting.


## 3. Comparative Analysis
<img width="905" height="583" alt="image" src="https://github.com/user-attachments/assets/1b14cde3-ab03-4c01-ba64-a9e7f3adb0b1" />


## 4. Key Observations

Few-Shot and CoT prompting consistently improved accuracy and structure.
Role-Based prompting produced the most engaging summaries for undergraduate learners.
Claude and ChatGPT delivered the most balanced performance, excelling in coherence and tone.
Gemini stood out for factual precision but sometimes leaned toward overly technical language.
Copilot, while useful for code-oriented tasks, lagged behind in summarizing long-form text.


## 5. Conclusion
The best combination for educational content delivery was Claude with Role-Based Prompting, closely followed by ChatGPT with Chain-of-Thought or Role-Based Prompting. These combinations provided summaries that were accurate, coherent, simple, fast, and student-friendly. Incorporating these prompting strategies can significantly improve content curation for research summaries aimed at undergraduate audiences.


# Result
Thus, the summarized Result section based on the experiment using the three prompt types (Straightforward, Tabular Format, Missing Word) and two AI platforms (ChatGPT and Claude).


